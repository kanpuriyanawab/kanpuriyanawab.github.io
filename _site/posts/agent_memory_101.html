<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-06-03">
<meta name="description" content="How Stateful Memory is Revolutionizing AI Agents and Applications">

<title>The AI Memory Layer Will Change Everything – Anshuman Mishra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../assets/images/pfp/varkala.jpg" rel="icon" type="image/jpeg">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-a1323aa62f39b50c9384c66a2e062d34.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/academicons-1.9.4/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/academicons-1.9.4/size.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="The AI Memory Layer Will Change Everything – Anshuman Mishra">
<meta property="og:description" content="How Stateful Memory is Revolutionizing AI Agents and Applications">
<meta property="og:image" content="https://www.heyyanshuman.com/posts/assets/agent_memory_101/memory_1.jpg">
<meta property="og:site_name" content="Anshuman Mishra">
<meta name="twitter:title" content="The AI Memory Layer Will Change Everything – Anshuman Mishra">
<meta name="twitter:description" content="How Stateful Memory is Revolutionizing AI Agents and Applications">
<meta name="twitter:image" content="https://www.heyyanshuman.com/posts/assets/agent_memory_101/memory_1.jpg">
<meta name="twitter:creator" content="@kanpuriyanawab">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Anshuman Mishra</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../pages/work.html"> 
<span class="menu-text">Work</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../pages/life.html"> 
<span class="menu-text">Life</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/kanpuriyanawab"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/anshuizme/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kanpuriyanawab"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://youtube.com/@1smollcoder"> <i class="bi bi-youtube" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://fullstackagents.substack.com"> <i class="bi bi-substack" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.fr/citations?user=70wh9jcAAAAJ"> 
<span class="menu-text"><i class="ai  ai-google-scholar" aria-label="google-scholar"></i></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The AI Memory Layer Will Change Everything</h1>
                  <div>
        <div class="description">
          How Stateful Memory is Revolutionizing AI Agents and Applications
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">Agents</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 3, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#context-window-bottleneck" id="toc-context-window-bottleneck" class="nav-link active" data-scroll-target="#context-window-bottleneck">Context Window Bottleneck:</a></li>
  <li><a href="#why-cant-we-just-have-infinite-context" id="toc-why-cant-we-just-have-infinite-context" class="nav-link" data-scroll-target="#why-cant-we-just-have-infinite-context">Why Can’t We Just Have Infinite Context?</a>
  <ul class="collapse">
  <li><a href="#lost-in-the-middle-even-big-windows-have-blind-spots" id="toc-lost-in-the-middle-even-big-windows-have-blind-spots" class="nav-link" data-scroll-target="#lost-in-the-middle-even-big-windows-have-blind-spots">“Lost in the Middle”: Even Big Windows Have Blind Spots</a></li>
  </ul></li>
  <li><a href="#defining-memory-in-ai-more-than-just-recent-chat-history" id="toc-defining-memory-in-ai-more-than-just-recent-chat-history" class="nav-link" data-scroll-target="#defining-memory-in-ai-more-than-just-recent-chat-history">Defining “Memory” in AI: More Than Just Recent Chat History</a></li>
  <li><a href="#another-challenge---llms-lack-focus" id="toc-another-challenge---llms-lack-focus" class="nav-link" data-scroll-target="#another-challenge---llms-lack-focus">Another challenge - LLMs lack focus!</a></li>
  <li><a href="#stateless-agents" id="toc-stateless-agents" class="nav-link" data-scroll-target="#stateless-agents">Stateless Agents</a></li>
  <li><a href="#stateful-agents" id="toc-stateful-agents" class="nav-link" data-scroll-target="#stateful-agents">Stateful Agents</a></li>
  <li><a href="#current-approaches-for-agentic-memory-layer" id="toc-current-approaches-for-agentic-memory-layer" class="nav-link" data-scroll-target="#current-approaches-for-agentic-memory-layer">Current Approaches for Agentic Memory layer</a></li>
  <li><a href="#the-human-element-feeling-understood" id="toc-the-human-element-feeling-understood" class="nav-link" data-scroll-target="#the-human-element-feeling-understood">The Human Element: Feeling Understood</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/kanpuriyanawab/edit/master/posts/agent_memory_101.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kanpuriyanawab/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In my opinion, the next major advancement in Applied AI won’t come from larger models or more training data, but from agents that can actually learn from experience. For that to happen, a robust memory layer is absolutely essential. In this blog, we’ll delve into why agents need such a memory layer and explore the exciting possibilities this unlocks. But first, to set the context, let’s understand the limitations of current agents:</p>
<section id="context-window-bottleneck" class="level2">
<h2 class="anchored" data-anchor-id="context-window-bottleneck">Context Window Bottleneck:</h2>
<p>The most simplest mental model to understand Context window is:</p>
<blockquote class="blockquote">
<p>Computer is to RAM as an LLM is to its context window.</p>
</blockquote>
<blockquote class="blockquote">
<p>Just as RAM determines how much data a computer can actively work with at any given moment, the context window limits how much information a large language model (LLM) can “see” and process at once.</p>
</blockquote>
<p>It acts as AI’s active short-term memory. In more simple words - it’s the amount of information - text/audio/video, that AI can “look at” or consider at any given point of time when generating a response. While you chat with an AI, your conversation history, up to a certain limit, fits into this window.</p>
<p>The trouble is, this window is finite. Remember those “maximum limit reached” alerts in Claude or ChatGPT, well we are talking about exactly that! While it’s true that these windows have been expanding (Gemini models having 10M context length), they are still fundamentally limited. This poses a huge challenge for:</p>
<p>→ <strong>Extended Conversations</strong> - Chats that go on for days, weeks, or months will inevitably exceed the window size.</p>
<p>→ <strong>Complex Document Analysis</strong> - Trying to understand or summarize very long documents, like a detailed research paper or a lengthy legal contract, becomes problematic if the whole thing doesn’t fit.</p>
<p>→ <strong>Long-Term Tasks</strong> - Any project or goal that requires consistent input and understanding over a long period is hampered if the AI keeps forgetting earlier stages.</p>
</section>
<section id="why-cant-we-just-have-infinite-context" class="level2">
<h2 class="anchored" data-anchor-id="why-cant-we-just-have-infinite-context">Why Can’t We Just Have Infinite Context?</h2>
<p>A fair question! The technical reason, as I understand it, is largely tied to the underlying <a href="https://arxiv.org/abs/1706.03762">transformer</a> architecture that powers many of these LLMs. The self-attention mechanism, which allows the model to weigh the importance of different parts of the input, generally has a computational and memory cost that increases quadratically with the length of the input sequence. Simply put, making the context window vastly larger makes the AI much, much slower and more expensive to run. While there’s ongoing research into more efficient architectures, just scaling up the current approach indefinitely isn’t practical.</p>
<section id="lost-in-the-middle-even-big-windows-have-blind-spots" class="level3">
<h3 class="anchored" data-anchor-id="lost-in-the-middle-even-big-windows-have-blind-spots">“Lost in the Middle”: Even Big Windows Have Blind Spots</h3>
<p>Even if we had incredibly long context windows, there’s another curious problem: LLMs don’t always use all the information within their context window equally well. Research, like the paper <a href="https://arxiv.org/abs/2307.03172">Lost in the Middle: How Language Models Use Long Contexts</a> has shown a fascinating U-shaped performance curve. This means:</p>
<ul>
<li><p>Models are often best at recalling and using information that appears at the <strong>very beginning</strong> of their input context (primacy bias).</p></li>
<li><p>They are also quite good with information at the <strong>very end</strong> of the context (recency bias).</p></li>
<li><p>However, performance can significantly <strong>degrade</strong> when they need to access and use information located somewhere in the <strong>middle</strong> of a long context.</p></li>
</ul>
<p><em>Imagine feeding an AI 20 documents to answer a question, and the key document is the 10th one. The AI might struggle to find or correctly use that key document more than if it were the 1st or the 20th. In some cases, performance when information is in the middle can be worse than if the AI had no documents at all and was just relying on its pre-trained knowledge! This phenomenon is seen even in models specifically designed for long contexts.</em></p>
<p><img src="assets/agent_memory_101/memory_1.jpg" class="img-fluid"></p>
<p>The consequence of these limitations is that many AI agents today are essentially stateless. Each interaction is largely isolated, leading to a lack of true personalization, repeated questions, and inconsistent behavior. It’s like having a brilliant personal assistant who, unfortunately, gets their memory wiped clean every morning.</p>
</section>
</section>
<section id="defining-memory-in-ai-more-than-just-recent-chat-history" class="level2">
<h2 class="anchored" data-anchor-id="defining-memory-in-ai-more-than-just-recent-chat-history">Defining “Memory” in AI: More Than Just Recent Chat History</h2>
<p>When I talk about building AI agents with memory, I’m envisioning something far more sophisticated than just extending the context window. I’m talking about the AI’s capacity to <strong>retain, recall, and utilize relevant information across extended periods, diverse tasks, and numerous interactions.</strong> This is what allows an AI to transition from being a stateless tool to a <strong>stateful companion</strong> – one that truly learns and evolves alongside its user.</p>
<p>I think it’s helpful to consider different types of memory, drawing inspiration from human cognition, which some AI memory systems are starting to model:</p>
<ul>
<li><p>Short-Term/Working Memory: This is the AI’s immediate “scratchpad,” analogous to the current context window. It holds what’s actively being processed.</p></li>
<li><p>Long-Term Memory: This is the persistent store of information. We can break this down further:</p>
<ul>
<li><p>Episodic Memory: Memories of specific events or interactions. For an AI, this would mean remembering past conversations with you, the specific advice it gave, or the tasks you worked on together.</p></li>
<li><p>Semantic Memory: General knowledge and facts. This includes the AI’s vast pre-trained knowledge, but also, crucially, facts it learns specifically about you (your preferences, goals, style) or about a particular domain you’re working in.</p></li>
<li><p>Procedural Memory: Knowledge of how to do things. For an AI, this could be remembering a multi-step process you often use, or learning the best way to present information to you.</p></li>
</ul></li>
</ul>
<p>I have a strong opinion here. The Dotcom era Dotcom era enabled businesses to move online - and Apps emerged, I think AI is going to bring hyper-personalization to these apps. And for that to happen this much depth of memory so crucial. Moreover, Agent memory is going to play very important role in maintaining coherence and consistency in its interactions. It will enable an agent to Learn and adapt from past successes and failures.</p>
</section>
<section id="another-challenge---llms-lack-focus" class="level2">
<h2 class="anchored" data-anchor-id="another-challenge---llms-lack-focus">Another challenge - LLMs lack focus!</h2>
<p>Beyond the context window size and the “lost in the middle” problem, there’s another tricky aspect: distractibility. I think this is a crucial point – it’s not just about how much the AI can see, but how clearly it can see it. If the important details are surrounded by noise, the AI can get sidetracked.</p>
<p>The paper <a href="https://arxiv.org/abs/2302.00093">Large Language Models Can Be Easily Distracted by Irrelevant Context</a> really drives this home. They created a special dataset called Grade-School Math with Irrelevant Context (GSM-IC) where math problems were intentionally mixed with useless information. What they found was that the performance of cutting-edge LLMs dropped dramatically when this irrelevant information was present. Even if all the necessary information is within the context window, adding just one irrelevant sentence could throw the model off. This tells me that even with larger context windows, we still need to be smart about how information is presented and processed.</p>
<p>The consequence of all these limitations – finite windows and “lost in the middle” effects – is that many AI agents today are essentially stateless. This is a really important concept, so let’s dive into it.</p>
</section>
<section id="stateless-agents" class="level2">
<h2 class="anchored" data-anchor-id="stateless-agents">Stateless Agents</h2>
<p>A stateless AI, in simple terms, is an AI that treats (almost) every interaction as a brand new one. It doesn’t have a persistent memory of your past conversations, preferences, or history beyond what fits in its immediate, fleeting context window.</p>
<p>Think about these scenarios, which I’m sure many of us have experienced:</p>
<p>→ <strong>The “Who Are You Again?” Syndrome</strong>: You’re in a long work session with an AI, perhaps coding or drafting a document. You’ve already told it your project name, your specific requirements, and your preferred style. Half an hour later, you ask it a follow-up question, and it responds as if it has no idea what project you’re even talking about.</p>
<p>→ <strong>Groundhog Day Problem-Solving</strong>: You’re working through a multi-step problem with an AI. It helps you with step 1. When you move to step 2, it seems to have forgotten the conclusions or data from step 1, forcing you to re-explain or re-feed information.</p>
<p>→ <strong>The Dietary Déjà Vu</strong>: You tell your AI assistant, “I’m a vegetarian.” It acknowledges this. The next day, you ask for dinner ideas, and it enthusiastically suggests a steakhouse. The “Mem0” paper has a great illustration of this exact problem (Figure 1 in their paper). Frustrating, right? That’s a stateless agent forgetting a critical piece of information once it falls out of the immediate context.</p>
<p>This statelessness is the arch-nemesis of hyper-personalization. It leads to inefficient interactions, repeated explanations, and a feeling that the AI, despite its power, doesn’t really “get” you or your ongoing needs. It’s like having that brilliant assistant I mentioned earlier, but one who gets their memory wiped clean every single morning.</p>
<p><img src="assets/agent_memory_101/memory_2.jpg" class="img-fluid"></p>
</section>
<section id="stateful-agents" class="level2">
<h2 class="anchored" data-anchor-id="stateful-agents">Stateful Agents</h2>
<p>Now, imagine the opposite: a stateful AI agent. This is an AI designed with a memory system that allows it to maintain a persistent, evolving understanding of you, your interactions, your preferences, and the facts relevant to your shared tasks, across multiple sessions and over long periods.</p>
<p>This isn’t just about remembering your name; it’s about building a continuous thread of understanding.</p>
<p>What could a truly stateful agent do?</p>
<ul>
<li><p>Remember Your Preferences, Proactively: It wouldn’t just avoid suggesting steak after you say you’re vegetarian; it might proactively say, “Since you’re vegetarian, how about this new pasta dish?” or “I found some great vegetarian recipes that align with your goal of eating healthier, which you mentioned last week.”</p></li>
<li><p>Recall Your Work Context: When you resume a coding project, it would remember your preferred coding style, the libraries you commonly use, the overall architecture of your project, and the specific problem you were trying to solve last time.</p></li>
<li><p>Build on Past Interactions: It could reference a discussion you had weeks ago, saying, “Remember when we were talking about marketing strategies for X? I found an article that expands on that idea.”</p></li>
<li><p>Learn Your Style: Over time, it would adapt to your communication style, the level of detail you prefer, and even your sense of humor, making interactions feel more natural and efficient.</p></li>
<li><p>Enable True Learning and Adaptation: A stateful agent can learn from its mistakes. If it gave you a suggestion that didn’t work out, it could store that “outcome” and avoid similar errors in the future. This is crucial for agents that need to perform complex tasks or make decisions.</p></li>
</ul>
<p>This statefulness transforms an AI from a generic tool into a genuine assistant, a collaborator, or even a companion that grows and learns with you.</p>
<p>I believe the next wave of killer apps won’t just be smart; they’ll be smart about you. And the engine driving this hyper-personalization will be these advanced memory systems. Think about how this could transform the apps we use every day:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 5%">
<col style="width: 33%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Category</th>
<th style="text-align: left;">Stateless</th>
<th style="text-align: left;">Stateful (with Memory)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>E-commerce &amp; Shopping</strong></td>
<td style="text-align: left;">You search for “running shoes” and get a generic list. Next week, it treats you like a new customer.</td>
<td style="text-align: left;">The AI remembers your shoe size, brand preference, and past purchases. When you search for “running gear,” it suggests compatible items like socks or running belts and might even recommend accessories in complementary colors to items you previously bought.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Productivity &amp; Work</strong></td>
<td style="text-align: left;">You ask your AI coding assistant to write a Python function. For the next request, it might use a completely different style, forgetting your preferences for comments or error handling.</td>
<td style="text-align: left;">The AI coding assistant remembers your common coding patterns (e.g., preference for async functions, using black for formatting) and provides suggestions that fit seamlessly into your existing codebase and personal style.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Learning &amp; Education</strong></td>
<td style="text-align: left;">An AI tutor gives you a lesson on fractions. The next day, it starts from scratch, unaware of the specific concepts you struggled with previously.</td>
<td style="text-align: left;">The AI tutor remembers you found a specific concept (e.g., improper fractions) tricky. It starts the next session with a recap of that point, offers a different explanation, or provides tailored practice problems before moving on.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Healthcare &amp; Wellness</strong></td>
<td style="text-align: left;">You ask for help to reduce stress, and the app provides a generic meditation exercise.</td>
<td style="text-align: left;">The AI remembers your specific stressors (e.g., work deadlines) and preferred calming activities (e.g., nature walks). It suggests a targeted 10-minute meditation for deadline pressure or recommends a short walk, making the advice highly relevant.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Personal Assistants</strong></td>
<td style="text-align: left;">A chatbot that can answer questions but has no memory of you, your preferences, or your past interactions.</td>
<td style="text-align: left;">An AI that remembers your goals, important names, favorite music, and even your mood patterns. It can offer encouragement and make suggestions that are truly relevant because they are rooted in a shared, remembered history.</td>
</tr>
</tbody>
</table>
</section>
<section id="current-approaches-for-agentic-memory-layer" class="level2">
<h2 class="anchored" data-anchor-id="current-approaches-for-agentic-memory-layer">Current Approaches for Agentic Memory layer</h2>
<ul>
<li><strong>MemGPT (now part of LettaAI)’s LlmOS-Inspired Approach:</strong> The <a href="https://arxiv.org/abs/2310.08560">MemGPT: Towards LLMs as Operating Systems</a> paper introduces “virtual context management,” where the LLM itself acts like an operating system for its memory. It intelligently manages a hierarchical memory system, with a limited “main context” (like RAM) for active processing and a larger “external context” (like disk storage, including archival and recall storage) for long-term information. The LLM uses function calls to page data between these tiers, effectively giving it an extended memory to handle tasks like large document analysis and multi-session chats where context far exceeds its physical window</li>
</ul>
<p><img src="assets/agent_memory_101/memory_3.png" class="img-fluid"></p>
<ul>
<li><strong>Mem0’s Approach to Dynamic Memory:</strong> The <a href="https://arxiv.org/abs/2504.19413">Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</a> paper outlines a scalable, memory-centric architecture designed for real-world applications. Memo’s system dynamically extracts salient information from conversations in an extraction phase (using historical context like summaries and recent messages) and then, in an update phase, uses an LLM with tool-calling capabilities to evaluate these new “candidate memories” against existing ones, deciding whether to ADD, UPDATE, DELETE, or take NOOP (no operation) to maintain a coherent knowledge base.</li>
</ul>
<p><img src="assets/agent_memory_101/memory_4.jpg" class="img-fluid"></p>
</section>
<section id="the-human-element-feeling-understood" class="level2">
<h2 class="anchored" data-anchor-id="the-human-element-feeling-understood">The Human Element: Feeling Understood</h2>
<p>There’s something deeply human about being remembered. When a friend recalls a small detail from a conversation months ago, it makes us feel valued and heard. I believe that as AI agents develop more sophisticated memory, our interactions with them will start to feel more meaningful.</p>
<p>It’s not about replacing human connection, of course. But for the tasks we delegate to AI, or the ways we use AI for support and companionship, memory will be key to building trust and fostering a sense of being genuinely understood. When an AI can consistently recall your context, preferences, and history, it reduces friction, saves you time, and makes the collaboration feel much more natural and effective.</p>
<p><strong>A Note on the Research That Inspired This Post:</strong></p>
<p>Throughout this piece, I’ve drawn inspiration and information from the work of many talented researchers and writers exploring the frontiers of AI memory. If you’re interested in digging deeper, here are some of the key resources I found particularly insightful:</p>
<ul>
<li><p>For understanding the challenges with how LLMs use long contexts, the paper <a href="https://arxiv.org/abs/2307.03172">Lost in the Middle: How Language Models Use Long Contexts (Liu et al., 2023)</a> is a must-read.</p></li>
<li><p>The concept of LLMs being easily sidetracked is well-explored in <a href="https://arxiv.org/abs/2302.00093">Large Language Models Can Be Easily Distracted by Irrelevant Context (Shi et al., 2023)</a>.</p></li>
<li><p>For an OS-inspired approach to memory management, check out “MemGPT: Towards LLMs as Operating Systems” (Packer et al., 2023).</p></li>
<li><p>The <a href="https://arxiv.org/abs/2504.19413">Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</a> paper (Chhikara et al., 2025) offers a look at a production-focused system with impressive results and graph-based memory.</p></li>
<li><p>The blogs from Letta (on RAG vs.&nbsp;Agent Memory, Memory Blocks, and Stateful Agents) and Mem0.ai (on Types of Memory, Making AI Companions Truly Personal, and Memory in Agents) provide excellent conceptual overviews and insights into building more personal AI.</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.heyyanshuman\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/kanpuriyanawab/edit/master/posts/agent_memory_101.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kanpuriyanawab/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>