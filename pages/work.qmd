---
# title: Work
aliases: 
  - /work
toc: true
---

## 2025

<!-- ### Building Production Ready Text to SQL Agent <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span> <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span><span style="font-size: 0.65em; font-weight: 600; background-color: #FEE2E2; color: #991B1B; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">YouTube</span>

As I venture into AI Consulting, I'm giving back to community via education. In this project I demonstrate how to build production ready AI Agent for task of text to sql generation and execution.

The assets related to this work can be found on [X](https://x.com/kanpuriyanawab/status/1931018241419477078), [github](https://github.com/kanpuriyanawab/awesome-ai-agents/tree/main). I also published [a blog](https://heyyanshuman.com/posts/text2sql_agent) for this. 
To stay upto-date with my work you can subscribe via [substack](https://fullstackagents.substack.com/p/building-production-ready-text-to). -->


<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/ezOhLC10uSQ?si=eC1KW1yHw6vw-ozV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> -->


<!-- ### The AI Memory Layer That will change everything <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span>

In this [blog](https://heyyanshuman.com/posts/agent_memory_101) we dive into Memory layer of AI and understand why stateful AI agents are path to hyperpersonalization and not the stateless once. -->


### Snapgenie

Building my first [SaaS](https://snapgenie.pro). One Photo. Endless Possibilities. Turn snappy pictures into professional shots.

### Qwen Model Family Integration in Keras  <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>

As a consultant for the Keras team, I led the integration of the state-of-the-art **Qwen model family** into KerasHub. This work made multiple versions of this powerful generative model, including its advanced Mixture-of-Experts variant, accessible to the global Keras community.

* **Qwen 3 & Qwen 2.5:** For both the [Qwen 3](https://github.com/keras-team/keras-hub/pull/2249) and [Qwen 2.5](https://github.com/keras-team/keras-hub/pull/2088) models, my contributions included implementing the core backbone, custom attention mechanisms, and building a robust checkpoint conversion pipeline.

* **Qwen-1.5 Mixture-of-Experts (MoE):** The integration of the [Qwen-1.5-MoE model](https://github.com/keras-team/keras-hub/pull/2163) presented unique challenges, particularly its high memory footprint. To address this, I engineered a memory-efficient MoE layer, adapting techniques from other advanced implementations to ensure the model was performant and accessible on standard hardware.


### Mixtral <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>
Through this work I developed support for [Mixtral](https://github.com/keras-team/keras-hub/pull/2196) model in Keras Hub, making it accessible to community.

## 2024

### JMLR Paper on Keras Multi-framework Models <span style="font-size: 0.65em; font-weight: 600; background-color: #FEF9C3; color: #854d0e; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Publication</span>

I co-authored a foundational paper for the **Journal of Machine Learning Research (JMLR)** detailing the multi-framework architecture of KerasCV and KerasNLP. The work showcases how these libraries were engineered to seamlessly support TensorFlow, PyTorch, and JAX.

* **Title:** [*KerasCV and KerasNLP: Multi-framework Models*](http://jmlr.org/papers/v25/24-0404.html)
* **Published:** Journal of Machine Learning Research (Volume 25, 2024)
* **My Role:** Co-author, contributing to the framework development and experimental validation.

### Youtube video <span style="font-size: 0.65em; font-weight: 600; background-color: #FEE2E2; color: #991B1B; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">YouTube</span>


<iframe width="560" height="315" src="https://www.youtube.com/embed/2Xo11kjJiZk?si=8WjEXpvuFG8jRfmx" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Data hack summit <span style="font-size: 0.65em; font-weight: 600; background-color: #dcfce7; color: #166534; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Talk</span>

I gave [this](https://www.analyticsvidhya.com/datahacksummit-2024/sessions/demystify-parallel-programming-hands-on-with-cuda-for-genai) talk at Data Hack Summit by Analytics Vidhya. It covered CUDA C fundamentals and core CUDA concepts like threads, blocks, and memory hierarchies. The session guided attendees through writing their first CUDA kernels, aiming to build the skills needed to optimize deep learning workloads.

## 2023

*I contributed to open source (mainly Keras) heavily throught the year. Gave a lot of talks travelling across the country.*

<!-- ### Supercharge KerasNLP Models with Wandb <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span>

While at Weights & Biases, I authored this official [report](https://wandb.ai/kanpuriyanawab/keras-nlp-x-wandb/reports/Supercharge-KerasNLP-Models-with-Wandb--Vmlldzo1Mjk1NjI2) on fine-tuning KerasNLP models for Semantic Similarity. The guide demonstrates how to leverage W&B Sweeps on the SNLI dataset to find optimal hyperparameters and train a high-performing model.

This was also [published](https://keras.io/examples/nlp/semantic_similarity_with_keras_hub/) on official keras website. -->

<!-- ### Generating High-quality Images with SD.Next, HuggingFace Diffusers and W&B <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span>

I documented my experiments with advanced diffusion models in this [report](https://wandb.ai/ml-colabs/automatic/reports/Generating-High-quality-Images-with-SD-Next-HuggingFace-Diffusers-and-W-B--Vmlldzo1NTYzMzQy). It's a comprehensive guide to generating high-quality images with SD.Next and HuggingFace Diffusers, emphasizing the use of W&B for complete observability and reproducibility. -->
### Google Summer of Code at TensorFlow <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>

My Google Summer of Code project was centered on expanding the KerasNLP library with foundational generative models. This experience evolved from implementing a single model to contributing core components, porting functionalities to Keras 3, and adding a series of highly-demanded models to the ecosystem.

* **Pioneering Foundational Models:**
    * **GPT-NeoX:** My main project was the end-to-end implementation of [GPT-NeoX](https://github.com/keras-team/keras-nlp/pull/1056), including its [preprocessor](https://github.com/keras-team/keras-nlp/pull/1093). Foreseeing the industry's shift, I proactively [ported the model to Keras 3](https://github.com/keras-team/keras-nlp/pull/1137) to ensure multi-backend support for TensorFlow, PyTorch, and JAX.
    * **Llama 2:** Responding to immediate community excitement, I applied my learnings from GPT-NeoX to quickly [contribute the Llama 2 model](https://github.com/keras-team/keras-nlp/pull/1203) to KerasNLP shortly after its release.

* **Developing Core API Components:**
    * **Generic Rotary Embedding:** I identified that the [Rotary Embedding layer](https://github.com/keras-team/keras-nlp/pull/1101) for GPT-NeoX was a fundamental component for most modern LLMs. I took the initiative to refactor and ship it as a [generic, reusable Keras layer](https://github.com/keras-team/keras-nlp/pull/1180), strengthening the core Keras API.
    * **New Keras Ops:** To support the models, I implemented and [contributed the `rsqrt` op](https://github.com/keras-team/keras-core/pull/708) and added [Root Mean Square scaling](https://github.com/keras-team/keras-core/pull/726) to the `LayerNormalization` layer, both of which are essential for modern generative architectures.

* **Enhancing Existing Models & Frameworks:**
    * **Albert & XLM-RoBERTa:** I expanded the capabilities of existing models by contributing missing task layers, including the [Classifier](https://github.com/keras-team/keras-nlp/pull/668) and [Masked LM](https://github.com/keras-team/keras-nlp/pull/725) heads for Albert, and the [Masked LM head](https://github.com/keras-team/keras-nlp/pull/950) for XLM-RoBERTa.
    * **Beam Sampler Port:** To deepen my understanding of decoding strategies, I ported the [Beam Sampler to Keras 3](https://github.com/keras-team/keras-nlp/pull/1181), contributing to the framework's multi-backend compatibility.
    * **Testing Improvements:** I significantly improved the CI/CD pipeline by [speeding up RoBERTa testing by ~3x](https://github.com/keras-team/keras-nlp/pull/897) and adding new [TPU tests](https://github.com/keras-team/keras-nlp/pull/839) for backbones.


### Talks <span style="font-size: 0.65em; font-weight: 600; background-color: #dcfce7; color: #166534; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Talk</span>
In later half of 2023, after I finished my GSoC, I decided to give back the knowledge I earned from OSS, to community. So I flew 11 cities throughout India giving talks and workshops on various topics related to NLP. Few of them are listed below:


1. [KerasNLP: From Words to Wisdom](https://twitter.com/gdg_nd/status/1709132486238724550?t=9V1JG6XwqQNJz6MEuiGqPA&s=08), on October 7, 2023 at DevFest New Delhi’23 .

2. [Modular NLP Workflows with KerasNLP](https://x.com/margaretmz/status/1706717545007546491?s=20), on September 29, 2023 at Google Developer Groups, Seattle.

3. [Supercharging Keras with WandB](https://twitter.com/tfugmumbai/status/1705456979756613978?s=20), on September 23, 2023 at TensorFlow User Group Mumbai.

4. [GSoC Success Secrets: Cracking the Code to OSS Excellence](https://www.linkedin.com/feed/update/urn:li:activity:7105945831630938112/), September 10, 2023 at National Institute of Technology, Warangal.

5. [Rethinking LLM Design with KerasNLP](https://twitter.com/kanpuriyanawab/status/1694540731783028926?s=20), on August 26, 2023 at TensorFlow User Group Hyderabad.

6. [KerasNLP for Starters](https://www.youtube.com/watch?v=KinLN4lA6Bg&t=3450s), on August 20, 2023 at TensorFlow User Group Durg

7. [Taking KerasNLP on GenAI Ride]() on July, 23, 2023 at TensorFlow User Group, Kolkata

8. [Re-imagining Keras in the evolving ML ecosystem](https://www.linkedin.com/posts/kanpuriyanawab_event-developercommunity-congratulations-activity-7086588533510934528-dS2y) on July 16, 2023 at Google I/O Extended'23 New Delhi.


<!-- 
### Data Parallel Training with KerasNLP <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span>
In this guide I demonstrated how to significantly accelerate NLP model training using data parallelism. I showcased the process of fine-tuning a pretrained BERT model from Keras Hub across multiple GPUs, leveraging TensorFlow's MirroredStrategy to efficiently scale deep learning workflows and dramatically reduce training time. 

This guide was officially [published](https://keras.io/examples/nlp/data_parallel_training_with_keras_hub/) on Keras website.


### Exploratory Data Analysis <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Blog</span>

In [this](https://www.kaggle.com/code/shivanshuman/one-stop-eda) Kaggle notebook, I developed a comprehensive template for Exploratory Data Analysis (EDA) on an enzyme substrate dataset. I demonstrated a full workflow, including visualizing feature correlations with heatmaps, analyzing distributions with histograms and box plots, and examining relationships between variables using pair plots to uncover key insights. -->


### Julia Contributions <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>
Metalhead is FluxML's (a julia deep learning package) official model zoo. I [contributed]((https://github.com/FluxML/Metalhead.jl/pull/210)) the UNet image segmentation model to Metalhead.jl, Julia's core computer vision library. By implementing the architecture with reference to the official PyTorch version, I made this popular model for semantic segmentation natively available to the FluxML community, fulfilling a key feature request for the library.

### Misc Bug Fixes <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>

- [Fix RotaryEmbedding import](https://github.com/keras-team/keras-nlp/pull/1217)
- [Fix Autograph error with perplexity metric](https://github.com/keras-team/keras-nlp/pull/1211)
- [Fix ModuleNotFoundError keras_nlp.models.xlnet](https://github.com/keras-team/keras-nlp/pull/1204)
- [Add compute_output_shape to tokenizer](https://github.com/keras-team/keras-nlp/pull/1166)
- [Default compilation for Albert, Distilbert, Roberta MaskedLM](https://github.com/keras-team/keras-nlp/pull/833)
- [Call super.config() in BartBackbone's get_config()](https://github.com/keras-team/keras-nlp/pull/818)
- [Add API exports for tokenizers documented on keras.io](https://github.com/keras-team/keras-nlp/pull/817)
- [Add API exports for metrics documented on keras.io](https://github.com/keras-team/keras-nlp/pull/816)
- [Add API exports for samplers documented on keras.io](https://github.com/keras-team/keras-nlp/pull/815)
- [Add API exports for models documented on keras.io](https://github.com/keras-team/keras-nlp/pull/814)
- [Move from_preset to base tokenizer classes](https://github.com/keras-team/keras-nlp/pull/673)
- [Add an add_prefix_space Arg in BytePairTokenizer](https://github.com/keras-team/keras-nlp/pull/715)

## 2022

*This year I mainly focused on Kaggling. It also marked my venture into OSS world.*

### CNN From Tensorflow to Pytorch <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>

In 2022, [Deepchem Project](https://deepchem.io) decided to migrate from tensorflow to pytorch. I [contributed](https://github.com/deepchem/deepchem/pull/2963) to this mission by porting their generic, scalable CNN models and layers to torch. I also fixed couple ([1]((https://github.com/deepchem/deepchem/pull/2988)), [2](https://github.com/deepchem/deepchem/pull/2964)) of bugs in the library that have gone unnoticed. 




### Neural Ordinary Differential Equations <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>
[Deepchem - Neural ODE tutorial 📚]

This [tutorial](https://deepchem.io/tutorials/about-node-using-torchdiffeq-in-deepchem/) demonstrates how to implement Neural Ordinary Differential Equations (Neural ODEs) within the DeepChem library by leveraging the torchdiffeq package. It explains how, instead of using discrete layers, a neural network can parameterize the derivative of a system's hidden state.

The [guide]((https://github.com/deepchem/deepchem/pull/2859)) walks through embedding a torchdiffeq ODE solver inside a PyTorch neural network to model continuous-time dynamics, making it possible to predict the future states of dynamic systems within the DeepChem ecosystem.



### G2Net Detecting Continuous Gravitational Waves <span style="font-size: 0.65em; font-weight: 600; background-color: #E0F3FF; color: #196F9E; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Kaggle</span>

I scored a bronze medal in this competition. The goal of this competition was to find continuous gravitational-wave signals. I developed a model sensitive enough to detect weak yet long-lasting signals emitted by rapidly-spinning neutron stars within noisy data. Here is one of the competition [notebooks]((https://www.kaggle.com/code/shivanshuman/kaggle-t4x2-multi-gpu-training-g2net)) that shows my approach to problem.


### ICR - Identifying Age-Related Conditions <span style="font-size: 0.65em; font-weight: 600; background-color: #E0F3FF; color: #196F9E; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">Kaggle</span>
The goal of this competition was to predict if a person has any of any medical conditions. Here are two notebooks that I submitted for the competition. One of them used an [ensemble based technique]((https://www.kaggle.com/code/shivanshuman/lb-0-23-ensemble-catboost-xgboost-lightgbm)) and the other used just LigthGBM. I used [optuna]((https://www.kaggle.com/code/shivanshuman/lightgbm-optuna-baseline)) library for hyperparameter optimization.



### Support safe serialization while pushing to Huggingface Hub from H2O llmstudio<span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span>
[PR](https://github.com/h2oai/h2o-llmstudio/pull/221)


### Deepmind - optax <span style="font-size: 0.65em; font-weight: 600; background-color: #fce8d1; color: #c55a11; padding: 3px 9px; border-radius: 12px; vertical-align: middle; text-transform: uppercase; letter-spacing: 0.5px;">OSS</span> 
[This]((https://github.com/google-deepmind/optax/pull/413)) is how I started open source. My first-ever contribution was a jax library called optax by google deepmind.
